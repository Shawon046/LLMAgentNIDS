{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3917b20f",
   "metadata": {},
   "source": [
    "Step 1: Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c8d71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, average_precision_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515975de",
   "metadata": {},
   "source": [
    "Step 2: Load and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7afdb03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 43)\n",
      "label\n",
      "0    0.53\n",
      "1    0.47\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0, tcp, ftp_data, SF, 491, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0, udp, other, SF, 146, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0, tcp, private, S0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0, tcp, http, SF, 232, 8153, 0, 0, 0, 0, 0, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0, tcp, http, SF, 199, 420, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                    0.17   \n",
       "1               0       0    0  ...                    0.00   \n",
       "2               0       0    0  ...                    0.10   \n",
       "3               0       0    0  ...                    1.00   \n",
       "4               0       0    0  ...                    1.00   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.03                         0.17   \n",
       "1                    0.60                         0.88   \n",
       "2                    0.05                         0.00   \n",
       "3                    0.00                         0.03   \n",
       "4                    0.00                         0.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "4                         0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "4                      0.00                  0.00                      0.00   \n",
       "\n",
       "   label                                               text  \n",
       "0      0  0, tcp, ftp_data, SF, 491, 0, 0, 0, 0, 0, 0, 0...  \n",
       "1      0  0, udp, other, SF, 146, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "2      1  0, tcp, private, S0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "3      0  0, tcp, http, SF, 232, 8153, 0, 0, 0, 0, 0, 1,...  \n",
       "4      0  0, tcp, http, SF, 199, 420, 0, 0, 0, 0, 0, 1, ...  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory of training and test data\n",
    "train_path = '/home/tauhid/llm_network_intrusion/nsl-kdd/KDDTrain+.csv'\n",
    "test_path = '/home/tauhid/llm_network_intrusion/nsl-kdd/KDDTest+.csv'\n",
    "\n",
    "# Load training data\n",
    "df = pd.read_csv(train_path, nrows=10000)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# Apply label encoding\n",
    "for dataset in [df, df_test]:\n",
    "    dataset['label'] = dataset['label'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "    dataset.drop(columns=['difficulty_score'], inplace=True)\n",
    "\n",
    "df['text'] = df.drop(columns='label').astype(str).agg(', '.join, axis=1)\n",
    "df_test['text'] = df_test.drop(columns='label').astype(str).agg(', '.join, axis=1)\n",
    "\n",
    "# Quick overview\n",
    "print(df.shape)\n",
    "print(df['label'].value_counts(normalize=True).round(2))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fb6b99",
   "metadata": {},
   "source": [
    "Step 3: Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a05e6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIDSDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length',\n",
    "                                  max_length=self.max_length, return_tensors='pt')\n",
    "        item = {k: v.squeeze() for k, v in encoding.items()}\n",
    "        item['labels'] = torch.tensor(label, dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa16d52",
   "metadata": {},
   "source": [
    "Step 4: Model Setup (Use distilGPT2 + AMP Ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43856e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"distilgpt2\"  # faster alternative\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c88bc",
   "metadata": {},
   "source": [
    "Step 5: Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af94597",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_dataset = NIDSDataset(df['text'], df['label'], tokenizer)\n",
    "test_dataset = NIDSDataset(df_test['text'], df_test['label'], tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d1a6a",
   "metadata": {},
   "source": [
    "Step 6: Training Loop with _fp16_, _tqdm_, and Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3972d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tauhid/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tauhid/venv/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Epoch 1:   0%|          | 0/1250 [00:00<?, ?it/s]/home/tauhid/venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Epoch 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 409/1250 [1:52:50<3:54:23, 16.72s/it]"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scaler = torch.cuda.amp.GradScaler()  # AMP scaler\n",
    "epochs = 10\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    train_preds, train_labels = [], []\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        preds = torch.argmax(outputs.logits, dim=-1)\n",
    "        train_preds.extend(preds.cpu().numpy())\n",
    "        train_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(train_labels, train_preds)\n",
    "    f1 = f1_score(train_labels, train_preds)\n",
    "    losses.append(epoch_loss / len(train_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {epoch_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save(model.state_dict(), f\"model_checkpoint_epoch_{epoch+1}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96748ade",
   "metadata": {},
   "source": [
    "Step 7: Plot Loss (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba707cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses, marker='o')\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7d10ab",
   "metadata": {},
   "source": [
    "Step 8: Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd7c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_preds, test_labels, prob_scores = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(batch['labels'].cpu().numpy())\n",
    "        prob_scores.extend(probs[:, 1].cpu().numpy())  # Probability of class 1 (Anomaly)\n",
    "\n",
    "# Compute metrics\n",
    "acc = accuracy_score(test_labels, test_preds)\n",
    "f1 = f1_score(test_labels, test_preds)\n",
    "recall = recall_score(test_labels, test_preds)\n",
    "precision_anomaly = precision_score(test_labels, test_preds, pos_label=1)\n",
    "precision_benign  = precision_score(test_labels, test_preds, pos_label=0)\n",
    "auroc = roc_auc_score(test_labels, prob_scores)\n",
    "auprc = average_precision_score(test_labels, prob_scores)\n",
    "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "# Print results\n",
    "print(\"\\n--- Test Evaluation ---\")\n",
    "print(f\"Accuracy            : {acc:.4f}\")\n",
    "print(f\"Precision (Benign)  : {precision_benign:.4f}\")\n",
    "print(f\"Precision (Anomaly) : {precision_anomaly:.4f}\")\n",
    "print(f\"Recall              : {recall:.4f}\")\n",
    "print(f\"F1 Score            : {f1:.4f}\")\n",
    "print(f\"AUROC               : {auroc:.4f}\")\n",
    "print(f\"AUPRC               : {auprc:.4f}\")\n",
    "print(f\"FPR (False Positive): {fpr:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
